{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1hqRu9n/nsMj7/G/C3bvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priya9112/Null-Class-Data-Science-Internship-/blob/main/Task_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK-3**\n",
        "Create a feature to translate the language from French to Tamil and\n",
        "    it should predict if the french word has only five letter if the french word has more than five letters or less than five letters the model should not translate the word"
      ],
      "metadata": {
        "id": "p02GGQZlyruj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJY2QBxYuSIp",
        "outputId": "c4ab63a6-3f5c-4294-f340-692d8289f3e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **French Sentence without 5-Letter French Words**"
      ],
      "metadata": {
        "id": "d9ffmh08zAAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "    return ' '.join([index_to_words.get(prediction, '') for prediction in np.argmax(logits, axis=-1) if prediction != 0])\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/french_to_tamil_model')\n",
        "\n",
        "with open('/content/drive/MyDrive/ft-json/french_tokenizer.json', 'r', encoding='utf8') as f:\n",
        "    french_tokenizer_json = json.load(f)\n",
        "french_tokenizer = tokenizer_from_json(french_tokenizer_json)\n",
        "\n",
        "with open('/content/drive/MyDrive/ft-json/tamil_tokenizer.json', 'r', encoding='utf8') as f:\n",
        "    tamil_tokenizer_json = json.load(f)\n",
        "tamil_tokenizer = tokenizer_from_json(tamil_tokenizer_json)\n",
        "\n",
        "with open('/content/drive/MyDrive/ft-json/sequence_length.json', 'r', encoding='utf8') as f:\n",
        "    max_tamil_sequence_length = json.load(f)\n",
        "\n",
        "def tokenize_word(word, tokenizer, max_length):\n",
        "    tokenized_word = tokenizer.texts_to_sequences([word])\n",
        "    return pad_sequences(tokenized_word, maxlen=max_length, padding='post')\n",
        "\n",
        "def translate_five_letter_words(french_sentence, model, french_tokenizer, tamil_tokenizer, max_length):\n",
        "    words = french_sentence.split()\n",
        "    translated_sentence = []\n",
        "    translated = False\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) == 5 and not translated:\n",
        "            tokenized_word = tokenize_word(word, french_tokenizer, max_length)\n",
        "            prediction = model.predict(tokenized_word)\n",
        "            translated_word = logits_to_text(prediction[0], tamil_tokenizer)\n",
        "            translated_sentence.append(translated_word.strip())\n",
        "            translated = True\n",
        "        else:\n",
        "\n",
        "            translated_sentence.append(word)\n",
        "\n",
        "    return ' '.join(translated_sentence)\n",
        "max_french_sequence_length = 8\n",
        "\n",
        "french_sentence = 'Ceci est une phrase courte.'\n",
        "translated_sentence = translate_five_letter_words(french_sentence, model, french_tokenizer, tamil_tokenizer, max_french_sequence_length)\n",
        "print('Original French sentence:')\n",
        "print(french_sentence)\n",
        "print()\n",
        "print('Translated Tamil sentence:')\n",
        "print(translated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVAnymmHvMol",
        "outputId": "f1c74e39-7b61-475b-9922-01116006f460"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original French sentence:\n",
            "Ceci est une phrase courte.\n",
            "\n",
            "Translated Tamil sentence:\n",
            "Ceci est une phrase courte.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **French Sentence with 5-Letter French Words**"
      ],
      "metadata": {
        "id": "_3ITzXz1zRPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "    return ' '.join([index_to_words.get(prediction, '') for prediction in np.argmax(logits, axis=-1) if prediction != 0])\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/french_to_tamil_model')\n",
        "\n",
        "with open('/content/drive/MyDrive/ft-json/french_tokenizer.json', 'r', encoding='utf8') as f:\n",
        "    french_tokenizer_json = json.load(f)\n",
        "french_tokenizer = tokenizer_from_json(french_tokenizer_json)\n",
        "\n",
        "with open('/content/drive/MyDrive/ft-json/tamil_tokenizer.json', 'r', encoding='utf8') as f:\n",
        "    tamil_tokenizer_json = json.load(f)\n",
        "tamil_tokenizer = tokenizer_from_json(tamil_tokenizer_json)\n",
        "\n",
        "with open('/content/drive/MyDrive/ft-json/sequence_length.json', 'r', encoding='utf8') as f:\n",
        "    max_tamil_sequence_length = json.load(f)\n",
        "\n",
        "def tokenize_word(word, tokenizer, max_length):\n",
        "    tokenized_word = tokenizer.texts_to_sequences([word])\n",
        "    return pad_sequences(tokenized_word, maxlen=max_length, padding='post')\n",
        "\n",
        "def translate_five_letter_words(french_sentence, model, french_tokenizer, tamil_tokenizer, max_length):\n",
        "    words = french_sentence.split()\n",
        "    translated_sentence = []\n",
        "    translated = False\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) == 5 and not translated:\n",
        "            tokenized_word = tokenize_word(word, french_tokenizer, max_length)\n",
        "            prediction = model.predict(tokenized_word)\n",
        "            translated_word = logits_to_text(prediction[0], tamil_tokenizer)\n",
        "            translated_sentence.append(translated_word.strip())\n",
        "            translated = True\n",
        "        else:\n",
        "            translated_sentence.append(word)\n",
        "\n",
        "    return ' '.join(translated_sentence)\n",
        "\n",
        "max_french_sequence_length = 8\n",
        "\n",
        "french_sentence = 'Le renard brun saute par-dessus le chien paresseux.'\n",
        "translated_sentence = translate_five_letter_words(french_sentence, model, french_tokenizer, tamil_tokenizer, max_french_sequence_length)\n",
        "print('Original French sentence:')\n",
        "print(french_sentence)\n",
        "print()\n",
        "print('Translated Tamil sentence:')\n",
        "print(translated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AGt39ElvkTs",
        "outputId": "326d57ac-44e1-42fe-eb98-9ddf8fdb467d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 740ms/step\n",
            "Original French sentence:\n",
            "Le renard brun saute par-dessus le chien paresseux.\n",
            "\n",
            "Translated Tamil sentence:\n",
            "Le renard brun தாண்டியது par-dessus நாயை தாண்டியது paresseux.\n"
          ]
        }
      ]
    }
  ]
}