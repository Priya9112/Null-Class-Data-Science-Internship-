{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMywMyv4ANGzF79Dotu3S4V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priya9112/Null-Class-Data-Science-Internship-/blob/main/Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPll6TIJfUJh",
        "outputId": "ed4024ad-5a14-4124-ea3d-059c0a145803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK-2\n",
        "###Implement beam search decoding for an NMT model to improve translation quality."
      ],
      "metadata": {
        "id": "hewQ3edpkcHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/english_to_french_model')\n",
        "\n",
        "with open('/content/drive/MyDrive/Json/english_tokenizer.json') as f:\n",
        "    english_tokenizer_json = json.load(f)\n",
        "english_tokenizer = tokenizer_from_json(english_tokenizer_json)\n",
        "\n",
        "with open('/content/drive/MyDrive/Json/french_tokenizer.json') as f:\n",
        "    french_tokenizer_json = json.load(f)\n",
        "french_tokenizer = tokenizer_from_json(french_tokenizer_json)\n",
        "\n",
        "with open('/content/drive/MyDrive/Json/sequence_length.json') as f:\n",
        "    max_french_sequence_length = json.load(f)\n",
        "\n",
        "print(f\"French tokenizer vocabulary size: {len(french_tokenizer.word_index)}\")\n",
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'  # Add padding token\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
        "\n",
        "def translate_greedy(input_sentence):\n",
        "    input_sequence = english_tokenizer.texts_to_sequences([input_sentence])\n",
        "    input_sequence = pad_sequences(input_sequence, maxlen=max_french_sequence_length)\n",
        "    translation = model.predict(input_sequence)\n",
        "    translation_text = logits_to_text(translation[0], french_tokenizer)\n",
        "    translation_text = ' '.join([word for word in translation_text.split() if word != '<PAD>'])\n",
        "    return translation_text\n",
        "\n",
        "def beam_search_decode(model, input_sequence, beam_width=10, max_seq_length=20, early_stopping_threshold=-10.0):\n",
        "    start_token = french_tokenizer.word_index.get('<start>', 0)\n",
        "    end_token = french_tokenizer.word_index.get('<end>', 0)\n",
        "    sequences = [[[start_token], 0.0]]\n",
        "\n",
        "    for step in range(max_seq_length):\n",
        "        all_candidates = list()\n",
        "        for seq, score in sequences:\n",
        "            if seq[-1] == end_token:\n",
        "                all_candidates.append((seq, score))\n",
        "            else:\n",
        "                target_seq = pad_sequences([seq], maxlen=max_seq_length, padding='post')\n",
        "                predictions = model.predict([input_sequence, target_seq])\n",
        "                top_k_indices = np.argsort(predictions[0, -1, :])[-beam_width:]\n",
        "                for idx in top_k_indices:\n",
        "                    candidate = [seq + [idx], score + np.log(predictions[0, -1, idx])]\n",
        "                    all_candidates.append(candidate)\n",
        "                print(f\"Step: {step}, Seq: {seq}, Top indices: {top_k_indices}\")\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)\n",
        "        sequences = ordered[:beam_width]\n",
        "        if sequences[0][1] < early_stopping_threshold:\n",
        "            break\n",
        "    return sequences[0][0]\n",
        "\n",
        "\n",
        "def sequence_to_text(sequence, tokenizer):\n",
        "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
        "    return ' '.join([index_to_words.get(idx, '<unk>') for idx in sequence if idx != 0])  # Exclude padding tokens\n",
        "\n",
        "# acc to data we trained our rnn model on\n",
        "input_sentences = [\n",
        "    'new jersey is sometimes quiet during autumn, and it is snowy in april.',\n",
        "    'the united states is usually chilly during july, and it is usually freezing in november.',\n",
        "    'california is usually quiet during march, and it is usually hot in june.',\n",
        "    'the united states is sometimes mild during june, and it is cold in september.'\n",
        "]\n",
        "\n",
        "for input_sentence in input_sentences:\n",
        "    print(f\"Input Sentence: {input_sentence}\")\n",
        "    input_sequence = english_tokenizer.texts_to_sequences([input_sentence])\n",
        "    input_sequence = pad_sequences(input_sequence, maxlen=max_french_sequence_length)\n",
        "\n",
        "    # I'm Translate using greedy decoding\n",
        "    translation_greedy = translate_greedy(input_sentence)\n",
        "    print('Greedy Translation:', translation_greedy)\n",
        "\n",
        "    # I'm Translate using beam search decoding\n",
        "    beam_width = 10\n",
        "    decoded_sequence = beam_search_decode(model, input_sequence, beam_width, max_french_sequence_length)\n",
        "    translation_beam_search = sequence_to_text(decoded_sequence, french_tokenizer)\n",
        "    print('Beam Search Translation:', translation_beam_search)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDyQUeN9fgzC",
        "outputId": "62ef10fe-6878-4e5c-f04c-5a3b0c8343d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French tokenizer vocabulary size: 344\n",
            "Input Sentence: new jersey is sometimes quiet during autumn, and it is snowy in april.\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Greedy Translation: new jersey est parfois calme pendant l' automne et il est neigeux en\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Beam Search Translation: new l' est neigeux pendant et jersey parfois il est automne calme en\n",
            "\n",
            "Input Sentence: the united states is usually chilly during july, and it is usually freezing in november.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Greedy Translation: les états unis est généralement froid en juillet et il gèle habituellement en novembre\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Beam Search Translation: habituellement en et gèle généralement en les est unis novembre juillet états froid il\n",
            "\n",
            "Input Sentence: california is usually quiet during march, and it is usually hot in june.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Greedy Translation: est généralement calme en mars et il est généralement chaud en juin\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Beam Search Translation: juin généralement chaud est il mars généralement en calme en est et\n",
            "\n",
            "Input Sentence: the united states is sometimes mild during june, and it is cold in september.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Greedy Translation: les états unis est parfois doux en juin et il fait froid en septembre\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Beam Search Translation: doux froid en en parfois il les états et septembre juin est fait unis\n",
            "\n"
          ]
        }
      ]
    }
  ]
}